{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, numpy, time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "N_ROWS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Grouping and Normalizing Officers:\n",
    "## Abstrat \n",
    "By grouping the typos and spanish translations of the 'bearer' and 'to the bearer' nodes, the amount of nodes to be matched is reduced by ~35%. Around 25% of the remaining nodes are exact duplicates (or 14% of the database).\n",
    "Furthermore, the same fuzzy matching algortihm used for the address dataset, found 11% of the remaining names to be over 85% similar.\n",
    "\n",
    "The officers database is hereby reduced by over 24%, while 11% of the remaining are similar.\n",
    "## 0. Import and cleansing:\n",
    "Importing the dataset all lowercase, adding a parent_id column. Removing details from some names; ex: { boshen ltd./137-93, boshen ltd./136-83, boshen ltd./134-61 }. An upgrade could move these details to the notes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>name</th>\n",
       "      <th>countries</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12000001</td>\n",
       "      <td>kim soo in</td>\n",
       "      <td>south korea</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12000002</td>\n",
       "      <td>tian yuan</td>\n",
       "      <td>china</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12000003</td>\n",
       "      <td>gregory john solomon</td>\n",
       "      <td>australia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12000004</td>\n",
       "      <td>matsuda masumi</td>\n",
       "      <td>japan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12000005</td>\n",
       "      <td>ho thuy nga</td>\n",
       "      <td>viet nam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    node_id                  name    countries  parent_id\n",
       "0  12000001            kim soo in  south korea          0\n",
       "1  12000002             tian yuan        china          0\n",
       "2  12000003  gregory john solomon    australia          0\n",
       "3  12000004        matsuda masumi        japan          0\n",
       "4  12000005           ho thuy nga     viet nam          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "officer_nodes = pandas.read_csv('data/nodes.officer.csv', usecols=['node_id', 'name', 'countries'])\n",
    "\n",
    "officer_nodes = officer_nodes.applymap( lambda _str: _str.lower() if isinstance( _str,str ) else _str )\n",
    "officer_nodes.name = officer_nodes.name.map( lambda _str: _str.split( '/' )[0] if isinstance( _str,str ) else _str )\n",
    "officer_nodes.name = officer_nodes.name.map( lambda _str: _str.replace( '.',' ' ) if isinstance( _str,str) else _str )\n",
    "officer_nodes['parent_id'] = 0\n",
    "\n",
    "officer_nodes.head( N_ROWS )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This database is relatively large, thankfully over 50% of the entries seem to be duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Total entries: 238402 \n",
      "* Duplicates: 121511 or 50%\n"
     ]
    }
   ],
   "source": [
    "def count_duplicates( df, col ):\n",
    "    duplicates = df[ df.duplicated([ col ]) ]\n",
    "\n",
    "    total = df.shape[0]\n",
    "    unique = len( df[ col ].unique() )\n",
    "\n",
    "    duplicate_count = total - unique\n",
    "    duplicate_percent = int( (duplicate_count * 100) / total )\n",
    "\n",
    "    print( f'* Total entries: {total} \\n* Duplicates: {duplicate_count} or {duplicate_percent}%' )\n",
    "\n",
    "count_duplicates( officer_nodes, 'name' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Normalizing \"bearer\" nodes:\n",
    "Bearers cannot be grouped into a single ID as they could represent different officers, thus only typos and translations are normalized.\n",
    "### TO CHECK:\n",
    "The conditions \"officer of the bearer\" and \"officer: the bearer\" are importand distinctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "the bearer        71421\n",
       "el portador        9351\n",
       "bearer              674\n",
       "the  bearer         114\n",
       "formia limited      107\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "officer_nodes.groupby('name').size().sort_values(ascending=False).head( N_ROWS )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping 'the barer/to the bearer', to their typos and spanish translations ('el portador/al portador'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL BEARER: 81740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name\n",
       "the bearer                         81629\n",
       "to the bearer                        111\n",
       "formia limited                       107\n",
       "north atlantic services limited      103\n",
       "first court limited                   96\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bearer_nodes = officer_nodes.name.isin( \n",
    "    ['the  bearer', 'el portador', 'bearer', 'baerer',\n",
    "    'the baerer', '-the bearer', 'the beare', 'the ebarer'] ) \n",
    "    \n",
    "to_bearer_nodes = officer_nodes.name.isin( \n",
    "    ['al protador', 'al portador', 'to bearer'] ) \n",
    "\n",
    "officer_nodes.loc[ bearer_nodes, 'name' ] = 'the bearer'\n",
    "officer_nodes.loc[ to_bearer_nodes, 'name' ] = 'to the bearer'\n",
    "\n",
    "all_bearer_nodes = officer_nodes.loc[ (officer_nodes.name == 'to the bearer') | (officer_nodes.name == 'the bearer') ]\n",
    "\n",
    "print( 'ALL BEARER:', all_bearer_nodes.shape[0] )\n",
    "officer_nodes.groupby('name').size().sort_values(ascending=False).head( N_ROWS )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Removing direct duplicates:\n",
    "25% of non \"bearer\" nodes are exact duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OTHER NODES\n",
      "* Total entries: 135871 \n",
      "* Duplicates: 34261 or 25%\n"
     ]
    }
   ],
   "source": [
    "all_bearer_nodes = officer_nodes.loc[ (officer_nodes.name == 'to the bearer') | (officer_nodes.name == 'the bearer') ]\n",
    "other_nodes = officer_nodes[ ~officer_nodes.isin(all_bearer_nodes) ].dropna()\n",
    "\n",
    "print('OTHER NODES')\n",
    "count_duplicates( other_nodes, 'name' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maping the parent's ids to their exact duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Total in: 22.011976718902588\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>name</th>\n",
       "      <th>countries</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>12000044</td>\n",
       "      <td>noble nominees limited</td>\n",
       "      <td>belize</td>\n",
       "      <td>12000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>12002698</td>\n",
       "      <td>tan sun-hua</td>\n",
       "      <td>philippines</td>\n",
       "      <td>12000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>12002971</td>\n",
       "      <td>omni capital assets ltd</td>\n",
       "      <td>anguilla</td>\n",
       "      <td>12002704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>12002974</td>\n",
       "      <td>omni capital assets ltd</td>\n",
       "      <td>anguilla</td>\n",
       "      <td>12002970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>12003131</td>\n",
       "      <td>lilay ltd</td>\n",
       "      <td>anguilla</td>\n",
       "      <td>12002703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      node_id                      name    countries parent_id\n",
       "43   12000044    noble nominees limited       belize  12000042\n",
       "183  12002698               tan sun-hua  philippines  12000007\n",
       "459  12002971  omni capital assets ltd      anguilla  12002704\n",
       "462  12002974   omni capital assets ltd     anguilla  12002970\n",
       "616  12003131                 lilay ltd     anguilla  12002703"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_duplicates = other_nodes.name.duplicated(keep=False)\n",
    "group_duplicates = other_nodes.loc[ other_duplicates ].groupby('name')\n",
    "\n",
    "def map_parent_id(df):\n",
    "    # parent_id is the first row's node_id\n",
    "    parent_id = df.node_id.iloc[0]\n",
    "    # children are the rest of the rows\n",
    "    df.iloc[ 1:, df.columns.get_indexer(['parent_id']) ] = parent_id\n",
    "    return df\n",
    "\n",
    "def gapply_parallel(df_group, func):\n",
    "    t1 = time.time()\n",
    "\n",
    "    df_list = [ group for name, group in df_group ]\n",
    "\n",
    "    with Pool( cpu_count() ) as pool:\n",
    "        results = pool.map(func, df_list)\n",
    "\n",
    "    result_df = pandas.concat( results )\n",
    "\n",
    "    print( f'* Total in:', time.time()-t1 )\n",
    "    return result_df\n",
    "\n",
    "exact_match = gapply_parallel( group_duplicates, map_parent_id )\n",
    "exact_match[[ 'node_id', 'parent_id' ]] = exact_match[ ['node_id', 'parent_id'] ].astype('Int64')\n",
    "\n",
    "officer_nodes.update( exact_match )\n",
    "officer_nodes[ officer_nodes.parent_id > 0 ].head( N_ROWS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Total Reduction: 14%\n"
     ]
    }
   ],
   "source": [
    "no_exact_duplicates = officer_nodes.loc[ officer_nodes.parent_id == 0 ]\n",
    "total_nodes = officer_nodes.shape[0]\n",
    "reduction = int( 100 - (no_exact_duplicates.shape[0] * 100) / total_nodes )\n",
    "\n",
    "print( f'* Total Reduction: {reduction}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fuzzy matching names:\n",
    "Separating the nodes to match:\n",
    "### NOTE: \n",
    "Due to the small string size, this method is not 100% accurate, another, better, matching algorithm might be;\n",
    "- Pruning; a simple linear algorithm to filter out irrelevant choices before the fuzzywuzzy match.\n",
    "- Combining: combine multiple fuzzy match algorithm; metaphone, soundex, et.. into a single result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122401"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_match = no_exact_duplicates.loc[ (no_exact_duplicates.name != 'the bearer') & (no_exact_duplicates.name != 'to the bearer') ]\n",
    "to_match.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing 122,549 nodes to each other would take an impossible amount of time and resources, thus we match the nodes by country groups, forgetting about outliers for now. Due to the small lenght of the strings a high threshold is set for the same matching algorithm used in the address dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "countries\n",
       "china                     17938\n",
       "hong kong                 10238\n",
       "british virgin islands     7788\n",
       "united kingdom             3971\n",
       "russia                     3357\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_match.groupby('countries').size().sort_values(ascending=False).head( N_ROWS )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy matching the strings:\n",
    "\n",
    "Again, this notebook has been limited for demonstration purposes and to spare you 40min and the real results are loaded later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Compared 3 in 0.0018012523651123047 sec\n",
      "* Compared 21 in 0.008484601974487305 sec\n",
      "* Compared 23 in 0.009030580520629883 sec\n",
      "* Compared 18 in 0.004841327667236328 sec\n",
      "* Compared 23 in 0.008645296096801758 sec\n",
      "* Compared 28 in 0.016125917434692383 sec\n",
      "* Compared 20 in 0.006034374237060547 sec\n",
      "* Compared 14 in 0.005669116973876953 sec\n",
      "* Compared 26 in 0.029726028442382812 sec\n",
      "* Compared 1 in 0.0005209445953369141 sec\n",
      "* Compared 34 in 0.016704797744750977 sec\n",
      "* Compared 16 in 0.0035254955291748047 sec\n",
      "* Compared 30 in 0.015091896057128906 sec\n",
      "* Compared 45 in 0.025414228439331055 sec\n",
      "* Compared 8 in 0.00164794921875 sec\n",
      "* Compared 14 in 0.004046916961669922 sec\n",
      "* Compared 41 in 0.021744489669799805 sec\n",
      "* Compared 34 in 0.02644968032836914 sec\n",
      "* Compared 23 in 0.01836109161376953 sec\n",
      "* Compared 20 in 0.004438877105712891 sec\n",
      "* Compared 38 in 0.022194623947143555 sec\n",
      "* Compared 17 in 0.004699230194091797 sec\n",
      "* Compared 17 in 0.004713773727416992 sec\n",
      "* Compared 7 in 0.0012426376342773438 sec\n",
      "* Compared 2 in 0.0004565715789794922 sec\n",
      "* Compared 20 in 0.005830049514770508 sec\n",
      "* Compared 27 in 0.0165557861328125 sec\n",
      "* Compared 2 in 0.0006265640258789062 sec\n",
      "* Compared 47 in 0.02819681167602539 sec\n",
      "* Compared 1 in 0.0067446231842041016 sec\n",
      "* Compared 16 in 0.005726814270019531 sec\n",
      "* Compared 21 in 0.013484954833984375 sec\n",
      "* Compared 32 in 0.01038670539855957 sec\n",
      "* Compared 2 in 0.0005850791931152344 sec\n",
      "* Compared 4 in 0.0007424354553222656 sec\n",
      "* Compared 28 in 0.010781049728393555 sec\n",
      "* Compared 21 in 0.006548166275024414 sec\n",
      "* Compared 27 in 0.011105775833129883 sec\n",
      "* Compared 41 in 0.01733231544494629 sec\n",
      "* Compared 2 in 0.0006129741668701172 sec\n",
      "* Compared 40 in 0.020817041397094727 sec\n",
      "* Compared 1 in 0.0005321502685546875 sec\n",
      "* Compared 4 in 0.0008084774017333984 sec\n",
      "* Compared 2 in 0.000579833984375 sec\n",
      "* Compared 35 in 0.013164520263671875 sec\n",
      "* Compared 3 in 0.0007569789886474609 sec\n",
      "* Compared 17 in 0.005278587341308594 sec\n",
      "* Compared 13 in 0.0029363632202148438 sec\n",
      "* Compared 19 in 0.006234169006347656 sec\n",
      "* Compared 27 in 0.020604848861694336 sec\n",
      "* Compared 26 in 0.010009050369262695 sec\n",
      "* Compared 4 in 0.0008275508880615234 sec\n",
      "* Compared 2 in 0.0008795261383056641 sec\n",
      "* Compared 15 in 0.0021953582763671875 sec\n",
      "* Compared 13 in 0.0030584335327148438 sec\n",
      "* Compared 9 in 0.0016775131225585938 sec\n",
      "* Compared 2 in 0.0005712509155273438 sec\n",
      "* Compared 10 in 0.003700733184814453 sec\n",
      "* Compared 29 in 0.010311603546142578 sec\n",
      "* Compared 48 in 0.016843318939208984 sec\n",
      "* Compared 2 in 0.0006160736083984375 sec\n",
      "* Compared 29 in 0.009783506393432617 sec\n",
      "* Compared 9 in 0.002245664596557617 sec\n",
      "* Compared 32 in 0.011357307434082031 sec\n",
      "* Compared 7 in 0.001260995864868164 sec\n",
      "* Compared 15 in 0.0038449764251708984 sec\n",
      "* Compared 8 in 0.0015680789947509766 sec\n",
      "* Compared 3 in 0.0006749629974365234 sec\n",
      "* Compared 19 in 0.0062906742095947266 sec\n",
      "* Compared 1 in 0.0005068778991699219 sec\n",
      "* Compared 27 in 0.009587526321411133 sec\n",
      "* Compared 9 in 0.001951456069946289 sec\n",
      "* Compared 6 in 0.0010864734649658203 sec\n",
      "* Compared 4 in 0.0009999275207519531 sec\n",
      "* Compared 38 in 0.016702651977539062 sec\n",
      "* Compared 19 in 0.005356311798095703 sec\n",
      "* Compared 2 in 0.0006003379821777344 sec\n",
      "* Compared 37 in 0.030389785766601562 sec\n",
      "* Compared 4 in 0.0009710788726806641 sec\n",
      "* Compared 14 in 0.0033783912658691406 sec\n",
      "* Compared 43 in 0.024253129959106445 sec\n",
      "* Compared 1 in 0.00046062469482421875 sec\n",
      "* Compared 6 in 0.0012950897216796875 sec\n",
      "* Compared 23 in 0.008707284927368164 sec\n",
      "* Compared 14 in 0.0029604434967041016 sec\n",
      "* Compared 5 in 0.0008101463317871094 sec\n",
      "* Compared 1 in 0.0004985332489013672 sec\n",
      "* Compared 35 in 0.01171422004699707 sec\n",
      "* Compared 27 in 0.010365962982177734 sec\n",
      "* Compared 16 in 0.00843954086303711 sec\n",
      "* Compared 36 in 0.01726841926574707 sec\n",
      "* Compared 8 in 0.0015943050384521484 sec\n",
      "* Compared 16 in 0.0020711421966552734 sec\n",
      "* Compared 7 in 0.0008001327514648438 sec\n",
      "* Compared 39 in 0.01177668571472168 sec\n",
      "* Total Elapsed Time: 0.5018243789672852\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import time\n",
    "\n",
    "# TODO: sort the groups by size, so the computation can start on the biggest group first (i.e: China with 20k address). This would decrease the total computation time.\n",
    "\n",
    "THRESHOLD = 85\n",
    "SELECTOR = 'name'\n",
    "GROUP = to_match.groupby('countries')\n",
    "LIMIT = 50\n",
    "\n",
    "def calculate_string_similarity(df):\n",
    "    t1 = time.time()\n",
    "\n",
    "    choices = set( df[ SELECTOR ].unique() )\n",
    "    seen = set()\n",
    "    results = dict()\n",
    "\n",
    "    choice_count = len(choices)\n",
    "    for i in range( choice_count-1 ):\n",
    "        choice = list(choices)[i]\n",
    "        if len(choice) < 2:\n",
    "            continue\n",
    "\n",
    "        seen.add(choice)\n",
    "        new_choices = choices.difference(seen)\n",
    "        if len(new_choices) == 0:\n",
    "            break\n",
    "\n",
    "        res = process.extract(choice, new_choices, scorer=fuzz.token_sort_ratio, limit=10000)\n",
    "        res = [ r[0] for r in res if r[1] > THRESHOLD ]\n",
    "\n",
    "        if len(res):\n",
    "            seen.update(res)\n",
    "            results[choice] = res\n",
    "        i += 1 \n",
    "\n",
    "    tt = time.time() - t1\n",
    "    print( f'* Compared {choice_count} in {tt} sec' )\n",
    "    return results\n",
    "\n",
    "def gapply_parallel(df_group, func):\n",
    "    t1 = time.time()\n",
    "\n",
    "    if LIMIT:\n",
    "        df_list = [ group for name, group in df_group if group.shape[0] < LIMIT ]\n",
    "    else:\n",
    "        df_list = [ group for name, group in df_group ]\n",
    "\n",
    "    results = {}\n",
    "    with Pool( cpu_count() ) as pool:\n",
    "        for res in pool.map(func, df_list):\n",
    "            results.update( res )\n",
    "\n",
    "    results = pandas.DataFrame.from_dict(results,  orient='index')\n",
    "    results.reset_index(inplace=True)\n",
    "\n",
    "    print( f'* Total Elapsed Time:', time.time()-t1 )\n",
    "    return results\n",
    "\n",
    "\n",
    "similar_str = gapply_parallel(GROUP, calculate_string_similarity)\n",
    "similar_str = similar_str.rename( {'index': 'parent' } , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maloku endrit</td>\n",
       "      <td>endrit maloku</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>norma graciela woscoff, roberto goldwaser, gab...</td>\n",
       "      <td>roberto goldwaser, norma graciela woscoff, gab...</td>\n",
       "      <td>gabriela gisela goldwaser, roberto goldwaser, ...</td>\n",
       "      <td>pablo javier isaac goldwaser, roberto goldwase...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maria inmaculada zamora bonet</td>\n",
       "      <td>maria immaculada zamora bonet</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>collette laurens</td>\n",
       "      <td>colette laurens</td>\n",
       "      <td>ms  colette laurens</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>julia bonet fite</td>\n",
       "      <td>julia bonet fiter</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              parent  \\\n",
       "0                                      maloku endrit   \n",
       "1  norma graciela woscoff, roberto goldwaser, gab...   \n",
       "2                      maria inmaculada zamora bonet   \n",
       "3                                   collette laurens   \n",
       "4                                   julia bonet fite   \n",
       "\n",
       "                                                   0  \\\n",
       "0                                      endrit maloku   \n",
       "1  roberto goldwaser, norma graciela woscoff, gab...   \n",
       "2                      maria immaculada zamora bonet   \n",
       "3                                    colette laurens   \n",
       "4                                  julia bonet fiter   \n",
       "\n",
       "                                                   1  \\\n",
       "0                                               None   \n",
       "1  gabriela gisela goldwaser, roberto goldwaser, ...   \n",
       "2                                               None   \n",
       "3                                ms  colette laurens   \n",
       "4                                               None   \n",
       "\n",
       "                                                   2     3  \n",
       "0                                               None  None  \n",
       "1  pablo javier isaac goldwaser, roberto goldwase...  None  \n",
       "2                                               None  None  \n",
       "3                                               None  None  \n",
       "4                                               None  None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_str.head( N_ROWS )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1.6565921306610107\n",
      "Total time: 0.29891467094421387\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>node_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13009880</td>\n",
       "      <td>12212223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12130663</td>\n",
       "      <td>12130662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12130663</td>\n",
       "      <td>12130661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12130663</td>\n",
       "      <td>12130660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12132951</td>\n",
       "      <td>12142237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parent_id   node_id\n",
       "0   13009880  12212223\n",
       "1   12130663  12130662\n",
       "2   12130663  12130661\n",
       "3   12130663  12130660\n",
       "4   12132951  12142237"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_match.set_index('node_id', inplace=True)\n",
    "\n",
    "def string_to_id(df):\n",
    "    def func(x):\n",
    "        if isinstance(x, str):\n",
    "            return to_match.index[ to_match.name == x ][0]\n",
    "        return 0\n",
    "        \n",
    "    return df.applymap(func)\n",
    "\n",
    "def flatten_to_pair(df):\n",
    "    return ( df.astype('Int64').where(df.ne(0))\n",
    "                    .set_index('parent')\n",
    "                    .stack()\n",
    "                    .reset_index(level=0, name='child_id') )\n",
    "\n",
    "def apply_parallel(df, func):\n",
    "    t1 = time.time()\n",
    "\n",
    "    _cpu_count = cpu_count()\n",
    "    df_split = numpy.array_split( df, _cpu_count )\n",
    "\n",
    "    with Pool( _cpu_count ) as pool:\n",
    "        res = pool.map( func, df_split )\n",
    "        try:\n",
    "            df = pandas.concat( res )\n",
    "        except ValueError:\n",
    "            # result could be a list of Nones\n",
    "            pass \n",
    "            \n",
    "    print(f'Total time:', time.time()-t1 )\n",
    "    return df\n",
    "\n",
    "similar_nodes = apply_parallel(similar_str, string_to_id)\n",
    "similar_nodes = apply_parallel(similar_nodes, flatten_to_pair)\n",
    "similar_nodes.rename( { 'parent' : 'parent_id', 'child_id' : 'node_id' }, axis=1, inplace=True)\n",
    "similar_nodes.reset_index(drop=True, inplace=True)\n",
    "\n",
    "similar_nodes.head( N_ROWS )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quantifying and saving results:\n",
    "Loading real similarity results and updating the officer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>countries</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12000001</th>\n",
       "      <td>kim soo in</td>\n",
       "      <td>south korea</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000002</th>\n",
       "      <td>tian yuan</td>\n",
       "      <td>china</td>\n",
       "      <td>12169128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000003</th>\n",
       "      <td>gregory john solomon</td>\n",
       "      <td>australia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000004</th>\n",
       "      <td>matsuda masumi</td>\n",
       "      <td>japan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000005</th>\n",
       "      <td>ho thuy nga</td>\n",
       "      <td>viet nam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name    countries  parent_id\n",
       "node_id                                               \n",
       "12000001            kim soo in  south korea          0\n",
       "12000002             tian yuan        china   12169128\n",
       "12000003  gregory john solomon    australia          0\n",
       "12000004        matsuda masumi        japan          0\n",
       "12000005           ho thuy nga     viet nam          0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_nodes = pandas.read_csv('data/edges.officers.csv')\n",
    "\n",
    "res = officer_nodes.set_index('node_id')\n",
    "similar_ = similar_nodes.set_index('node_id')\n",
    "\n",
    "res.update(similar_)\n",
    "res.parent_id = res.parent_id.astype('Int64')\n",
    "\n",
    "res.head( N_ROWS )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantifying result:\n",
    "## WRONG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reduction: 24%\n"
     ]
    }
   ],
   "source": [
    "no_dup = res[ res.parent_id == 0 ].shape[0]\n",
    "total = res.shape[0]\n",
    "reduction = int( 100 - (no_dup*100)/total)\n",
    "\n",
    "print( f'Total reduction: {reduction}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results might be better saved as new \"similar to\" nodes in a \"similar.nodes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update \"data/clean.edges.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bit72ba89a531ef4df18e1af0f065f1e4d6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
